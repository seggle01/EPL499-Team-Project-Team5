{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dc7d7b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Your imports\n",
    "from text_processing.pre_processing import preprocessing_text\n",
    "from glove.glove_controller import load_glove, tweet_to_glove_vector\n",
    "from vit import VisionTransformerWithLearnableAux\n",
    "\n",
    "RANDOM_STATE = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "33c2e5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Set up autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37664da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TweetEval...\n",
      "TweetEval: 24942 samples\n",
      "Balancing TweetEval...\n",
      "  Before: Class 0=7093, Class 1=17849, Ratio=2.52\n",
      "  After:  Class 0=17849, Class 1=17849, Ratio=1.00\n",
      "\n",
      "Loading your original data...\n",
      "Your data: 14186 samples\n",
      "Balancing your data...\n",
      "  Before: Class 0=7093, Class 1=7093, Ratio=1.00\n",
      "  After:  Class 0=7093, Class 1=7093, Ratio=1.00\n",
      "\n",
      "Loading SST-2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eggle\\anaconda3\\envs\\ML\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\eggle\\.cache\\huggingface\\hub\\datasets--glue. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 67349/67349 [00:00<00:00, 717870.85 examples/s]\n",
      "Generating validation split: 100%|██████████| 872/872 [00:00<00:00, 192203.12 examples/s]\n",
      "Generating test split: 100%|██████████| 1821/1821 [00:00<00:00, 358718.18 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST-2: 67349 samples\n",
      "Balancing SST-2...\n",
      "  Before: Class 0=29780, Class 1=37569, Ratio=1.26\n",
      "  After:  Class 0=37569, Class 1=37569, Ratio=1.00\n",
      "\n",
      "============================================================\n",
      "COMBINING DATASETS\n",
      "============================================================\n",
      "\n",
      "Combined train: 125022 samples\n",
      "  From TweetEval: 35698\n",
      "  From your data: 14186\n",
      "  From SST-2: 75138\n",
      "\n",
      "Final distribution:\n",
      "label\n",
      "0    62511\n",
      "1    62511\n",
      "Name: count, dtype: int64\n",
      "Ratio: 1.00\n",
      "\n",
      "Test: 6347 samples\n",
      "Test distribution:\n",
      "label\n",
      "0    3972\n",
      "1    2375\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "FINAL DATASET:\n",
      "Train: 125022 samples (Balanced: TweetEval + Your data + SST-2)\n",
      "Test:  6347 samples (Your original test set)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Load Data\n",
    "# ====================================\n",
    "\n",
    "print(\"Loading TweetEval...\")\n",
    "dataset = load_dataset('tweet_eval', 'sentiment')\n",
    "\n",
    "# Process TweetEval train data\n",
    "train_texts = dataset['train']['text']\n",
    "train_labels = [0 if l == 0 else 1 if l == 2 else -1 for l in dataset['train']['label']]\n",
    "df_tweet_eval = pd.DataFrame({'text': train_texts, 'label': train_labels})\n",
    "df_tweet_eval = df_tweet_eval[df_tweet_eval['label'] != -1]  # Remove neutral\n",
    "\n",
    "print(f\"TweetEval train: {len(df_tweet_eval)} samples\")\n",
    "\n",
    "# Load YOUR original training data\n",
    "print(\"Loading your original training data...\")\n",
    "df_your_train = pd.read_csv('../../../data/twitter_sentiment_train.csv')[['text', 'label']]\n",
    "\n",
    "print(f\"Your original train: {len(df_your_train)} samples\")\n",
    "\n",
    "# Stack (Combine) Both Training Sets\n",
    "df_train = pd.concat([df_tweet_eval, df_your_train], ignore_index=True)\n",
    "\n",
    "# Shuffle the combined training data\n",
    "df_train = df_train.sample(frac=1, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "\n",
    "print(f\"Combined train: {len(df_train)} samples\")\n",
    "print(f\"  From TweetEval: {len(df_tweet_eval)}\")\n",
    "print(f\"  From your data: {len(df_your_train)}\")\n",
    "\n",
    "# Use YOUR original test set\n",
    "df_test = pd.read_csv('../../../data/twitter_sentiment_test.csv')[['text', 'label']]\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTest: {len(df_test)} samples\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL DATASET:\")\n",
    "print(f\"Train: {len(df_train)} (TweetEval + Your data)\")\n",
    "print(f\"Test:  {len(df_test)} (Your original test set)\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7e6c6817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing train: 100%|██████████| 125022/125022 [00:51<00:00, 2441.67it/s]\n",
      "Preprocessing test: 100%|██████████| 6347/6347 [00:02<00:00, 2347.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe from cache: glove\\glove.pkl\n",
      "Loaded 1193514 word vectors from cache\n",
      "Creating GloVe embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding train: 100%|██████████| 125022/125022 [00:02<00:00, 42555.62it/s]\n",
      "Embedding test: 100%|██████████| 6347/6347 [00:00<00:00, 38491.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe train shape: (125022, 200)\n",
      "GloVe test shape: (6347, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Preprocessing and GloVe Embeddings\n",
    "# ====================================\n",
    "\n",
    "print(\"\\nPreprocessing texts...\")\n",
    "clean_tokens_train = [preprocessing_text(t) for t in tqdm(df_train['text'], desc=\"Preprocessing train\")]\n",
    "clean_tokens_test = [preprocessing_text(t) for t in tqdm(df_test['text'], desc=\"Preprocessing test\")]\n",
    "clean_text_train = [' '.join(tokens) for tokens in clean_tokens_train]\n",
    "clean_text_test = [' '.join(tokens) for tokens in clean_tokens_test]\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = r\"C:\\Users\\eggle\\Downloads\\glove.twitter.27B\\glove.twitter.27B.200d.txt\"\n",
    "EMBED_DIM = 200\n",
    "glove_vectors = load_glove(glove_path, EMBED_DIM, use_cache=True)\n",
    "\n",
    "# Create GloVe embeddings\n",
    "print(\"Creating GloVe embeddings...\")\n",
    "glove_train = np.vstack([tweet_to_glove_vector(t, glove_vectors, EMBED_DIM) \n",
    "                         for t in tqdm(clean_text_train, desc=\"Embedding train\")])\n",
    "glove_test  = np.vstack([tweet_to_glove_vector(t, glove_vectors, EMBED_DIM) \n",
    "                         for t in tqdm(clean_text_test, desc=\"Embedding test\")])\n",
    "\n",
    "# Extract labels\n",
    "y_train = df_train['label'].values\n",
    "y_test = df_test['label'].values\n",
    "\n",
    "print(f\"GloVe train shape: {glove_train.shape}\")\n",
    "print(f\"GloVe test shape: {glove_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2b98f84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Datasets created\n",
      "Train batches: 977, Test batches: 50\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Simple Dataset (Back to Original)\n",
    "# ====================================\n",
    "\n",
    "class GloVeImageDataset(Dataset):\n",
    "    \"\"\"Dataset for GloVe vectors reshaped as images.\"\"\"\n",
    "    \n",
    "    def __init__(self, glove_vectors, labels, height=20, width=10):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        glove_vectors : np.array\n",
    "            Array of shape (num_samples, 200).\n",
    "        labels : np.array\n",
    "            Array of shape (num_samples,).\n",
    "        height : int\n",
    "            Image height for reshaping.\n",
    "        width : int\n",
    "            Image width for reshaping.\n",
    "        \"\"\"\n",
    "        # Reshape to (num_samples, 1, height, width) - add channel dimension\n",
    "        self.glove_vectors = glove_vectors.reshape(-1, 1, height, width)\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # x is already (1, height, width) from reshape above\n",
    "        x = torch.FloatTensor(self.glove_vectors[idx])\n",
    "        y = torch.LongTensor([self.labels[idx]])[0]\n",
    "        return x, y\n",
    "\n",
    "# Prepare data\n",
    "train_dataset = GloVeImageDataset(\n",
    "    glove_train,\n",
    "    y_train,\n",
    "    height=20,\n",
    "    width=10\n",
    ")\n",
    "\n",
    "test_dataset = GloVeImageDataset(\n",
    "    glove_test,\n",
    "    y_test,\n",
    "    height=20,\n",
    "    width=10\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"\\nDatasets created\")\n",
    "print(f\"Train batches: {len(train_loader)}, Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "50e368da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cuda\n",
      "Model parameters: 1,727,202\n"
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Initialize Model (Original ViT)\n",
    "# ====================================\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "num_epochs = 20\n",
    "\n",
    "model = VisionTransformerWithLearnableAux(\n",
    "    glove_dim=200,\n",
    "    embed_dim=200,\n",
    "    d_ff=1000,\n",
    "    num_heads=5,\n",
    "    layers=3,\n",
    "    num_classes=2,\n",
    "    dropout=0.1,\n",
    "    num_auxiliary_patches=3,\n",
    "    mode=\"fine-tuning\"\n",
    ").to(device)\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "338fc595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training Vision Transformer on GloVe Embeddings\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 977/977 [00:14<00:00, 69.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Loss: 0.5385 | Test Acc: 0.8528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 977/977 [00:13<00:00, 72.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Loss: 0.5028 | Test Acc: 0.8568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 977/977 [00:14<00:00, 68.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Loss: 0.4964 | Test Acc: 0.8499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 977/977 [00:12<00:00, 75.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Loss: 0.4921 | Test Acc: 0.8547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 977/977 [00:12<00:00, 81.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Loss: 0.4878 | Test Acc: 0.8549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 977/977 [00:12<00:00, 80.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Loss: 0.4850 | Test Acc: 0.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:   1%|          | 11/977 [00:00<00:11, 83.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[128]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m logits = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m loss = criterion(logits, batch_y)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eggle\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eggle\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:28\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, glove_vectors, mask)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eggle\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eggle\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eggle\\Desktop\\Work\\EPL499-Team-Project\\src\\bert_approach\\test\\vit.py:122\u001b[39m, in \u001b[36mLayer.forward\u001b[39m\u001b[34m(self, input, mask)\u001b[39m\n\u001b[32m    120\u001b[39m norm_out = \u001b[38;5;28mself\u001b[39m.layer_norm_1(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Apply Multi Head Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m attention_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m attention_out = \u001b[38;5;28mself\u001b[39m.dropout(attention_out)\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# Residual connection\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eggle\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eggle\\anaconda3\\envs\\ML\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eggle\\Desktop\\Work\\EPL499-Team-Project\\src\\bert_approach\\test\\vit.py:434\u001b[39m, in \u001b[36mMultiHeadAttention.forward\u001b[39m\u001b[34m(self, QKV, mask)\u001b[39m\n\u001b[32m    430\u001b[39m V = V.view(batch_size, src_len, \u001b[38;5;28mself\u001b[39m.num_heads, \u001b[38;5;28mself\u001b[39m.d_k).transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)\n\u001b[32m    431\u001b[39m \u001b[38;5;66;03m# Shape: [batch_size, num_heads, seq_len, d_k]\u001b[39;00m\n\u001b[32m    432\u001b[39m \n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# 3. Apply scaled dot-product attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m attention_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[38;5;66;03m# 4. Concatenate heads and project back to d_model\u001b[39;00m\n\u001b[32m    437\u001b[39m attention_out = attention_out.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous().view(\n\u001b[32m    438\u001b[39m     batch_size, tgt_len, d_model\n\u001b[32m    439\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\eggle\\Desktop\\Work\\EPL499-Team-Project\\src\\bert_approach\\test\\vit.py:366\u001b[39m, in \u001b[36mMultiHeadAttention.scaled_dot_product_attention\u001b[39m\u001b[34m(self, Q, K, V, mask)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28mself\u001b[39m.Q = Q\n\u001b[32m    364\u001b[39m \u001b[38;5;66;03m# Calculate Attention Scores\u001b[39;00m\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# Step 1 : Q x K.T x d_k ^ -1/2\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m scores = (\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m / \u001b[38;5;28mself\u001b[39m.sqrt_d_k)\n\u001b[32m    367\u001b[39m \u001b[38;5;66;03m# Step 2 : Apply Mask(Optional)\u001b[39;00m\n\u001b[32m    368\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ====================================\n",
    "# Training Loop (Original)\n",
    "# ====================================\n",
    "best_acc = 0.0\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Vision Transformer on GloVe Embeddings\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_x, batch_y in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        logits = model(batch_x)\n",
    "        loss = criterion(logits, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            batch_x = batch_x.to(device)\n",
    "            logits = model(batch_x)\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(batch_y.numpy())\n",
    "    \n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {train_loss/len(train_loader):.4f} | Test Acc: {acc:.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Best Test Accuracy: {best_acc:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e1a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.86      0.92      0.89      3972\n",
      "    Positive       0.84      0.76      0.80      2375\n",
      "\n",
      "    accuracy                           0.86      6347\n",
      "   macro avg       0.85      0.84      0.84      6347\n",
      "weighted avg       0.86      0.86      0.85      6347\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=['Negative', 'Positive']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
