{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMKyuWJiZeIz"
      },
      "source": [
        "# Twitter Sentiment Classification: Positive vs. Negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RovOyx_ea_g_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.read_csv('../data/twitter_sentiment_train.csv')\n",
        "df_test  = pd.read_csv('../data/twitter_sentiment_test.csv')\n",
        "\n",
        "# Shuffle train set\n",
        "df_train = df_train.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "H-7r2TLCbFCR"
      },
      "outputs": [],
      "source": [
        "int_to_label = {1: 'Positive', 0: 'Negative'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "zVrCdHS3bC48",
        "outputId": "67320ea9-c804-486b-dea3-7583af5c6c4b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user r u going to Vancouver's Pride Parade th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the lucky $2 bills will be joining me at digi ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I miss when Sarah Palin was a bigger deal, she...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We're looking forward to hearing the result to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I thought this may have been entertaining afte...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0  @user r u going to Vancouver's Pride Parade th...      1\n",
              "1  the lucky $2 bills will be joining me at digi ...      1\n",
              "2  I miss when Sarah Palin was a bigger deal, she...      0\n",
              "3  We're looking forward to hearing the result to...      1\n",
              "4  I thought this may have been entertaining afte...      0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "U36XFnxmbD_e"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import string\n",
        "from textblob import TextBlob\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from pre_processing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('../data/profanity.txt', 'r') as f: \n",
        "    profanity_words = f.readlines()\n",
        "profanity_words = [s.strip() for s in profanity_words]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Extraction Checklist\n",
        "\n",
        "1. Profanity words count\n",
        "2. Sentiment and Subjectivity \n",
        "3. Emoji Sentiment + Emoticon e.g :), ðŸ˜‚, :((\n",
        "3. Fully Capitalized\n",
        "4. Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "PXULQoAAbfwO"
      },
      "outputs": [],
      "source": [
        "def count_all_capital_tokens(text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Counts the number of fully capitalized tokens (all letters uppercase) in a given text.\n",
        "    Returns: {'all_capital_token_count': count}\n",
        "    \"\"\"\n",
        "    matches = re.findall(r'\\b[A-Z][A-Z]+\\b', text)\n",
        "    return {'all_capital_token_count': len(matches)}\n",
        "\n",
        "def count_punctuation(text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Counts the occurrences of each punctuation mark in a given text.\n",
        "    Returns: {'punctuation_char1': count1, 'punctuation_char2': count2, ...}\n",
        "    \"\"\"\n",
        "    punct_occur = {}\n",
        "    for char in string.punctuation:\n",
        "        punct_occur[char] = 0\n",
        "    for char in text:\n",
        "        if char in string.punctuation:\n",
        "            punct_occur[char] += 1\n",
        "    return punct_occur\n",
        "\n",
        "def count_profanity_words(text: str, profanity_list: list) -> dict:\n",
        "    \"\"\"\n",
        "    Counts the number of profanity words in a given text using a predefined list.\n",
        "    Returns: {'profanity_word_count': count}\n",
        "    \"\"\"\n",
        "    count = 0\n",
        "    # Normalize both input and the word list using the to_lower() function\n",
        "    profanity_list = [s.lower() for s in profanity_list]\n",
        "    tokenized_sent = run_pipeline(text, [word_tokenize_sentence, to_lower])\n",
        "    for sent in tokenized_sent:\n",
        "        for token in sent:\n",
        "            if token in profanity_list:\n",
        "                count += 1\n",
        "    return {'profanity_word_count': count}\n",
        "\n",
        "def count_sad_emoticons(text: str):\n",
        "    \"\"\"\n",
        "    Returns the occurrences of sad emoticons.\n",
        "    Returns: {\n",
        "      \"sad_emoticon\": count\n",
        "    }\n",
        "    \"\"\"\n",
        "    # Sad, crying, angry, and negative emoticons\n",
        "    matches = re.findall(r':\\(|:\\||:\\/|:\\\\|:\\'\\(|>:\\(|D:|:<|:c|;\\(|T_T|T\\.T', text)\n",
        "    return {\"sad_emoticon\": len(matches)}\n",
        "\n",
        "def count_happy_emoticons(text: str):\n",
        "    \"\"\"\n",
        "    Returns the occurrences of happy emoticons.\n",
        "    Returns: {\n",
        "      \"happy_emoticon\": count\n",
        "    }\n",
        "    \"\"\"\n",
        "    # Happy, excited, laughing, and positive emoticons\n",
        "    matches = re.findall(r':\\)|:D|;D|=\\)|;-\\)|:\\}\\)|:>|=\\]|8\\)|;-D|XD|xD|x-D|X-D|<3|:\\*|;-\\*|;\\)|=D', text)\n",
        "    return {\"happy_emoticon\": len(matches)}\n",
        "\n",
        "\n",
        "import json\n",
        "from textblob import TextBlob\n",
        "import emoji\n",
        "\n",
        "# Load emoji JSON\n",
        "with open(\"../data/emoji_polarity.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    emoji_json = json.load(f)\n",
        "\n",
        "# Load emoticon JSON\n",
        "with open(\"../data/unicode_polarity.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    emoticon_json = json.load(f)\n",
        "\n",
        "# Merge both dictionaries\n",
        "combined_sentiment = {**emoji_json, **emoticon_json}\n",
        "\n",
        "def get_sentiment_and_subjectivity(text: str) -> dict:\n",
        "    blob = TextBlob(text)\n",
        "    pol = blob.sentiment.polarity\n",
        "    subj = blob.sentiment.subjectivity\n",
        "    \n",
        "    tb_pos = pol if pol > 0 else 0\n",
        "    tb_neg = abs(pol) if pol < 0 else 0\n",
        "\n",
        "    # Find all emojis and emoticons in text\n",
        "    items_in_text = [ch for ch in text if ch in emoji.EMOJI_DATA]  # emojis\n",
        "    # emoticons (like :) ;D) â€” check by splitting text\n",
        "    for em in combined_sentiment:\n",
        "        if em in text and em not in items_in_text:\n",
        "            items_in_text.append(em)\n",
        "\n",
        "    if items_in_text:\n",
        "        pos_list = [combined_sentiment[i][\"positivity\"] for i in items_in_text if i in combined_sentiment]\n",
        "        neg_list = [combined_sentiment[i][\"negativity\"] for i in items_in_text if i in combined_sentiment]\n",
        "\n",
        "        if pos_list:\n",
        "            avg_pos = sum(pos_list) / len(pos_list)\n",
        "            avg_neg = sum(neg_list) / len(neg_list)\n",
        "            final_pos = (tb_pos + avg_pos) / 2\n",
        "            final_neg = (tb_neg + avg_neg) / 2\n",
        "        else:\n",
        "            final_pos, final_neg = tb_pos, tb_neg\n",
        "    else:\n",
        "        final_pos, final_neg = tb_pos, tb_neg\n",
        "\n",
        "    return {\n",
        "        \"positive_sentiment\": final_pos,\n",
        "        \"negative_sentiment\": final_neg,\n",
        "        \"subjectivity\": subj\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocessing_text(text):\n",
        "    # Classical preprocessing steps\n",
        "    text = twokenize.tokenizeRawTweetText(text)\n",
        "    text = to_lower(text)\n",
        "    text = remove_stopwords(text)\n",
        "    text = lemmatize(text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6/6 [00:05<00:00,  1.09it/s]\n"
          ]
        }
      ],
      "source": [
        "feature_functions = [\n",
        "    count_punctuation,\n",
        "    lambda text: count_profanity_words(text, profanity_words),\n",
        "    count_all_capital_tokens,\n",
        "    count_sad_emoticons,\n",
        "    count_happy_emoticons,\n",
        "    get_sentiment_and_subjectivity\n",
        "]\n",
        "\n",
        "X_train = df_train.drop(columns='label')\n",
        "X_test = df_test.drop(columns='label')\n",
        "\n",
        "for func in tqdm(feature_functions):\n",
        "    results = X_train['text'].apply(lambda x: func(str(x))).tolist()\n",
        "    temp_df = pd.DataFrame(results)\n",
        "\n",
        "    temp_df.reset_index(drop=True, inplace=True)\n",
        "    X_train.reset_index(drop=True, inplace=True)\n",
        "    X_train = pd.concat([X_train, temp_df], axis=1)\n",
        "\n",
        "    results = X_test['text'].apply(lambda x: func(str(x))).tolist()\n",
        "    temp_df = pd.DataFrame(results)\n",
        "\n",
        "    temp_df.reset_index(drop=True, inplace=True)\n",
        "    X_test.reset_index(drop=True, inplace=True)\n",
        "    X_test = pd.concat([X_test, temp_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "text",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "!",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "\"",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "#",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "$",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "%",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "&",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "'",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "(",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": ")",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "*",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "+",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": ",",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "-",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": ".",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "/",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": ":",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": ";",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "<",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "=",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": ">",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "?",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "@",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "[",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "\\",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "]",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "^",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "_",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "`",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "{",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "|",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "}",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "~",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "profanity_word_count",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "all_capital_token_count",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "sad_emoticon",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "happy_emoticon",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "positive_sentiment",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "negative_sentiment",
                  "rawType": "float64",
                  "type": "float"
                },
                {
                  "name": "subjectivity",
                  "rawType": "float64",
                  "type": "float"
                }
              ],
              "ref": "12fb80a7-fd2f-48f7-acae-3478b3e32738",
              "rows": [
                [
                  "0",
                  "@user r u going to Vancouver's Pride Parade this Sunday, Aug 2 ? Wud be awesome 4 all !",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0.375",
                  "0.0",
                  "0.6166666666666667"
                ],
                [
                  "1",
                  "the lucky $2 bills will be joining me at digi tomorrow",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0.3333333333333333",
                  "0.0",
                  "0.8333333333333334"
                ],
                [
                  "2",
                  "I miss when Sarah Palin was a bigger deal, she was so easy to make fun of. Saturday night live got so fucking lucky with her.",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "2",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0.24060606060606063",
                  "0.0",
                  "0.5733333333333334"
                ],
                [
                  "3",
                  "We're looking forward to hearing the result together - 12.30pm Friday at Thor's Tipi on Parliament St - find out with us!",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "2",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "2",
                  "1",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0.0",
                  "0.0",
                  "0.0"
                ],
                [
                  "4",
                  "I thought this may have been entertaining after nicki's moment but it's actually very painful",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "2",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0",
                  "0.0",
                  "0.20499999999999996",
                  "0.85"
                ]
              ],
              "shape": {
                "columns": 40,
                "rows": 5
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>!</th>\n",
              "      <th>\"</th>\n",
              "      <th>#</th>\n",
              "      <th>$</th>\n",
              "      <th>%</th>\n",
              "      <th>&amp;</th>\n",
              "      <th>'</th>\n",
              "      <th>(</th>\n",
              "      <th>)</th>\n",
              "      <th>...</th>\n",
              "      <th>|</th>\n",
              "      <th>}</th>\n",
              "      <th>~</th>\n",
              "      <th>profanity_word_count</th>\n",
              "      <th>all_capital_token_count</th>\n",
              "      <th>sad_emoticon</th>\n",
              "      <th>happy_emoticon</th>\n",
              "      <th>positive_sentiment</th>\n",
              "      <th>negative_sentiment</th>\n",
              "      <th>subjectivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@user r u going to Vancouver's Pride Parade th...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.616667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the lucky $2 bills will be joining me at digi ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I miss when Sarah Palin was a bigger deal, she...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.240606</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.573333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We're looking forward to hearing the result to...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I thought this may have been entertaining afte...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.205</td>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 40 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  !  \"  #  $  %  &  '  (  \\\n",
              "0  @user r u going to Vancouver's Pride Parade th...  1  0  0  0  0  0  1  0   \n",
              "1  the lucky $2 bills will be joining me at digi ...  0  0  0  1  0  0  0  0   \n",
              "2  I miss when Sarah Palin was a bigger deal, she...  0  0  0  0  0  0  0  0   \n",
              "3  We're looking forward to hearing the result to...  1  0  0  0  0  0  2  0   \n",
              "4  I thought this may have been entertaining afte...  0  0  0  0  0  0  2  0   \n",
              "\n",
              "   )  ...  |  }  ~  profanity_word_count  all_capital_token_count  \\\n",
              "0  0  ...  0  0  0                     0                        0   \n",
              "1  0  ...  0  0  0                     0                        0   \n",
              "2  0  ...  0  0  0                     1                        0   \n",
              "3  0  ...  0  0  0                     0                        0   \n",
              "4  0  ...  0  0  0                     0                        0   \n",
              "\n",
              "   sad_emoticon  happy_emoticon  positive_sentiment  negative_sentiment  \\\n",
              "0             0               0            0.375000               0.000   \n",
              "1             0               0            0.333333               0.000   \n",
              "2             0               0            0.240606               0.000   \n",
              "3             0               0            0.000000               0.000   \n",
              "4             0               0            0.000000               0.205   \n",
              "\n",
              "   subjectivity  \n",
              "0      0.616667  \n",
              "1      0.833333  \n",
              "2      0.573333  \n",
              "3      0.000000  \n",
              "4      0.850000  \n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "execution_count": 269,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\eggle\\anaconda3\\envs\\EPL499\\Lib\\site-packages\\sklearn\\utils\\validation.py:1406: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ],
      "source": [
        "X_train_features = X_train.drop(columns=['text'])\n",
        "X_test_features = X_test.drop(columns=['text'])\n",
        "\n",
        "y_train = df_train.drop(columns=['text'])\n",
        "y_test = df_test.drop(columns=['text'])\n",
        "\n",
        "model = SGDClassifier(\n",
        "    loss='log_loss',\n",
        "    learning_rate='constant',\n",
        "    eta0=0.01,\n",
        "    random_state=123\n",
        ")\n",
        "\n",
        "model.fit(X_train_features, y_train)\n",
        "y_pred = model.predict(X_test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.81      0.65      0.72      3972\n",
            "    positive       0.56      0.74      0.64      2375\n",
            "\n",
            "    accuracy                           0.69      6347\n",
            "   macro avg       0.68      0.70      0.68      6347\n",
            "weighted avg       0.72      0.69      0.69      6347\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=['negative', 'positive']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'neg': 0.0, 'pos': 1.0, 'compound': 0.5859}\n"
          ]
        }
      ],
      "source": [
        "import emoji\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "def analyze_sentiment_no_neutral(text):\n",
        "    text = emoji.demojize(text)\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    scores = analyzer.polarity_scores(text)\n",
        "    \n",
        "    # remove 'neu' key\n",
        "    filtered_scores = {k: v for k, v in scores.items() if k != 'neu'}\n",
        "    return filtered_scores\n",
        "\n",
        "# Example\n",
        "text = \"xD\"\n",
        "print(analyze_sentiment_no_neutral(text))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
